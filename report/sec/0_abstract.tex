\begin{abstract}
Gaussian Splatting has emerged as a powerful technique for representing visual data, yet its potential for producing learned representations remains underexplored. In this work, we investigate the use of autoencoders to learn compact representations of images modeled as 2D Gaussian Splats. We construct a dataset of Gaussian Splats derived from CIFAR-10 images and implement multiple autoencoder architectures, including convolutional and ResNet-based models. Our experiments reveal that while autoencoding Gaussian Splats enables efficient compression and structured representation learning, visual reconstruction accuracy remains a challenge. We compare Splat-based encoding with conventional pixel-based methods, and discuss future directions for improving representation quality and interpretability. This study provides insights into the viability of Gaussian Splats as a learned visual representation and their potential applications in neural compression and generative modeling.
\end{abstract}