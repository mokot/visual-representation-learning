\section{Introduction}
\label{sec:introduction}

Recent advances in neural rendering and generative modeling have demonstrated the effectiveness of Gaussian Splatting for representing images and 3D scenes. In this work, we explore the novel task of autoencoding Gaussian Splats, employing autoencoders (AEs) to learn compact representations of images modeled as 2D Gaussian Splats. Our primary objectives are twofold: \textit{(1)} to construct and train an AE for Gaussian Splat representations of images and \textit{(2)} to compare its performance against a standard AE trained directly on raw image data. 

The importance of this problem arises from the growing need for efficient and flexible representations of visual data. Gaussian Splats offer a structured and parametric alternative to pixel-based representations, encapsulating key image features such as position, scale, rotation, opacity, and color in a compact form. This representation aligns well with modern neural rendering techniques and has the potential to enhance interpretability and compression efficiency.

We utilize Gaussian Splats and AEs due to their complementary strengths. Gaussian Splatting has proven to be a powerful representation technique for reconstructing visual data with high accuracy while being inherently adaptable to multi-resolution settings. AEs, on the other hand, provide a well-established framework for extracting meaningful latent representations and reducing data dimensionality in an unsupervised manner. A further focus of this work is the compression capability of Gaussian Splats. Unlike traditional pixel-based approaches, where compression often relies on feature extraction in a high-dimensional space, Gaussian Splats inherently provide a more structured, lower-dimensional representation of images.

Our contributions in this study include: \textit{(1)} the creation of a dataset consisting of trained Gaussian Splats derived from CIFAR-10 images, enabling further research on learned Splat representations, \textit{(2)} the design and implementation of an AE specifically tailored for Gaussian Splats, exploring different architectural choices and their impact on reconstruction quality, and \textit{(3)} a comparative analysis of Gaussian Splat-based autoencoding against conventional pixel-based autoencoding to evaluate reconstruction performance and compression efficacy. We aim to provide insights into the potential of Gaussian Splats as a learned visual representation and contribute to broader research on neural compression and generative modeling.

The remainder of this report is structured as follows: Section \ref{sec:background} presents essential background on Gaussian Splatting and AEs. Section \ref{sec:methodology} details our dataset, Splatting process, AE design, and experimental setup. Section \ref{sec:results} presents our findings on different Splatting techniques and AE architectures. Section \ref{sec:discussion} presents interpretations of the results, highlighting key insights, limitations, and future directions. Finally, Section \ref{sec:conclusion} summarizes our contributions.  
