\section{Introduction}
\label{sec:introduction}

Recent advances in neural rendering and generative modeling have demonstrated the effectiveness of 	Gaussian splatting for representing images and 3D scenes. In this work, we explore the novel task of 	autoencoding for Gaussian splats, where we leverage autoencoders (AEs) to learn compact representations of images modeled as 2D Gaussian splats. Our primary objectives are twofold: \textit{(1)} to construct and train an autoencoder for Gaussian splat representations of images and \textit{(2)} to compare its performance against a standard autoencoder trained directly on raw image data. 

The importance of this problem arises from the growing need for efficient and flexible representations of visual data. Gaussian splats offer a structured and parametric alternative to pixel-based representations, encapsulating key image features such as position, scale, rotation, opacity, and color in a compact form. This representation aligns well with modern neural rendering techniques and has the potential to enhance interpretability, adaptability, and compression efficiency in learned visual representations.

We adopt Gaussian splats and autoencoders for this task due to their complementary strengths. Gaussian splatting has proven to be a powerful representation technique for reconstructing visual data with high accuracy while being inherently adaptable to multi-resolution settings. Autoencoders, on the other hand, provide a well-established framework for extracting meaningful latent representations and reducing data dimensionality in an unsupervised manner. By combining these approaches, we aim to investigate whether autoencoding in the Gaussian splat space can yield benefits in terms of compression efficiency, reconstruction quality, and feature disentanglement compared to standard pixel-based autoencoding.

A key focus of this work is on the compression capabilities of Gaussian splats. Unlike traditional pixel-based approaches, where compression often relies on feature extraction in a high-dimensional space, Gaussian splats inherently provide a more structured, lower-dimensional representation of images. This opens up opportunities for novel encoding strategies that take advantage of the underlying parametric nature of the splat representation.

Our contributions in this study include:
\begin{itemize}
    \item The creation of a dataset consisting of trained Gaussian splats derived from CIFAR-10 images, enabling further research on learned splat representations.
    \item The design and implementation of an autoencoder specifically tailored for Gaussian splats, exploring different architectural choices and their impact on reconstruction quality.
    \item A comparative analysis of Gaussian splat-based autoencoding against conventional pixel-based autoencoding to evaluate reconstruction performance and compression efficacy.
\end{itemize}

By addressing these objectives, we aim to provide insights into the potential of Gaussian splats as a learned visual representation and contribute to the broader research on neural compression and generative modeling.

The remainder of this report is structured as follows: Section \ref{sec:background} provides essential background on Gaussian splatting and autoencoders. Section \ref{sec:methodology} details our dataset, splatting process, autoencoder design, and experimental setup. Section \ref{sec:results} presents our findings on different splatting techniques, autoencoder architectures, and various evaluation approaches. Section \ref{sec:discussion} interprets the results, highlighting key insights, limitations, and future directions. Finally, Section \ref{sec:conclusion} summarizes our contributions.  
