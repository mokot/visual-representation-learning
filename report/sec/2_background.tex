\section{Background}
\label{sec:background}

\subsection{Gaussian Splats}
\label{bg-Gaussian Splatting}
Recently, scene representation and novel-view synthesis techniques making use of machine learning methods have steadily gained attention. One of the most popular frameworks in this category are Neural Radiance Fields (NeRFs) $\cite{}{}$, able to produce high quality implicit representations of scenes. Typically, NeRFs do this by optimizing a deep neural network using a volumetric and continuous representation of the scene, using techniques such as volumetric ray marching. In spite of various improvements to increase the efficiency of this framework \cite{Mildenhall2020NeRF}, achieving high visual quality through NeRFs remains computationally expensive due to the training cost of the neural network, in addition to a high rendering cost. To address these issues, the Gaussian Splatting framework was proposed.

Through Gaussian Splatting, instead of learning a continuous implicit representation of a scene, scenes are explicitly represented through a set of points using a large number of Gaussian primitives. The Gaussian ellipsoids constituting a scene have a set of learnable parameters controlling properties of the reconstruction, such as position, opacity, anisotropic covariance, and colors. In addition to providing a high reconstruction quality, Gaussian Splatting provides much faster rendering, being able to produce novel-views in real time. Gaussian Splatting achieves this by using rasterization-based rendering, which, in contrast to the rendering used by NeRFs, does not require sampling points.

Although Gaussian Splatting was originally formulated for the reconstruction of 3D-scenes, and is often studied in that domain, this work considers 2D Gaussian Splatting, alleviating some of the challenges involved in the process of autoencoding Gaussian Splats.

\subsection{Auto-Encoders}
\label{bg-ae}
Auto-Encoders \cite{Ballard1987ModularLI} are one of the most widely used models in the field of unsupervised learning. The first component of a conventional AE is the encoder, which maps the input data into a lower-dimensional \textit{latent} space. The second component of this architecture is the decoder, which reconstructs the original input from the reduced latent space. The primary function of AEs is to learn a compact and efficient representation of the input data in the latent space. This compact representation has proven useful for feature extraction and dimensionality reduction \cite{Zabalza2016NovelSS} in particular.

Over time, various modifications have improved the capabilities of AEs. Some notable variants include Denoising Autoencoders (DAE) \cite{Vincent2008ExtractingAC}, which introduce noise into input data to improve robustness; Sparse Autoencoders (SAE) \cite{ranzato2006efficient}, which enforce sparsity constraints on the hidden layer for better feature selection; and Variational Autoencoders (VAE) \cite{Kingma2014SemisupervisedLW}, which integrate probabilistic modeling for generative applications, and Convolutional Autoencoders (CAE) \cite{masci2011stacked}, which employ convolutional layers for an improved structuring of image data.

In this work, Gaussian Splats are encoded and reconstructed using a variety of AE architectures, investigating the potential of generating meaningful, accurate and compact representations of Splat data.