{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Note: This is a hack to allow importing from the parent directory\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "sys.path.append(str(Path().resolve().parent))\n",
        "sys.path.append(str(Path().resolve().parent / \"submodules/resnet-18-autoencoder/src\"))\n",
        "\n",
        "# Note: Ignore warnings, be brave (YoLo)\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from PIL import Image\n",
        "from models import ResNetAutoencoder, ConvAutoencoder\n",
        "from gsplat import rasterization_2dgs\n",
        "from data import CIFAR10GaussianSplatsDataset\n",
        "from utils import (\n",
        "    noop_collate,\n",
        "    transform_autoencoder_input,\n",
        "    transform_autoencoder_output,\n",
        ")\n",
        "from constants import (\n",
        "    CIFAR10_TRANSFORM,\n",
        "    CIFAR10_INVERSE_TRANSFORM,\n",
        "    TENSOR_TRANSFORM,\n",
        "    PIL_TRANSFORM,\n",
        ")\n",
        "from classes.resnet_autoencoder import AE as DefaultResNetAutoencoder\n",
        "\n",
        "plt.style.use(\"../style/main.mpltstyle\")\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "def collect_samples_by_label(\n",
        "    data, n_samples, test_loader, class_to_index, index_to_class\n",
        "):\n",
        "    data = {k: [] for k in class_to_index.keys()}\n",
        "    all_labels_filled = False\n",
        "\n",
        "    for batch in test_loader:\n",
        "        if all_labels_filled:\n",
        "            break\n",
        "\n",
        "        for image, index, splat in batch:\n",
        "            label = index_to_class[index]\n",
        "            if len(data[label]) < n_samples:\n",
        "                data[label].append((image, splat))\n",
        "\n",
        "            all_labels_filled = all(len(v) >= n_samples for v in data.values())\n",
        "            if all_labels_filled:\n",
        "                break\n",
        "\n",
        "    return data\n",
        "\n",
        "\n",
        "def compression_ratio(image: Image.Image, latent_tensor: torch.Tensor):\n",
        "    image_array = np.array(image)\n",
        "    image_tensor = torch.tensor(image_array).float()\n",
        "\n",
        "    input_size = image_tensor.numel()\n",
        "    latent_size = latent_tensor.numel()\n",
        "\n",
        "    compression_ratio = input_size / latent_size\n",
        "\n",
        "    return compression_ratio\n",
        "\n",
        "\n",
        "def custom_forward(\n",
        "    means_model, quats_model, scales_model, opacities_model, colors_model, splat\n",
        "):\n",
        "    means_model = means_model.to(DEVICE)\n",
        "    quats_model = quats_model.to(DEVICE)\n",
        "    scales_model = scales_model.to(DEVICE)\n",
        "    opacities_model = opacities_model.to(DEVICE)\n",
        "    colors_model = colors_model.to(DEVICE)\n",
        "    splat = splat.to(DEVICE)\n",
        "    x = transform_autoencoder_input(splat, \"dict\")\n",
        "    x_means = x[\"means\"].unsqueeze(0)\n",
        "    x_quats = x[\"quats\"].unsqueeze(0)\n",
        "    x_scales = x[\"scales\"].unsqueeze(0)\n",
        "    x_opacities = x[\"opacities\"].unsqueeze(0)\n",
        "    x_colors = x[\"colors\"].unsqueeze(0)\n",
        "    y_means = means_model.encoder(x_means)\n",
        "    y_quats = quats_model.encoder(x_quats)\n",
        "    y_scales = scales_model.encoder(x_scales)\n",
        "    y_opacities = opacities_model.encoder(x_opacities)\n",
        "    y_colors = colors_model.encoder(x_colors)\n",
        "    y = {\n",
        "        \"means\": y_means,\n",
        "        \"quats\": y_quats,\n",
        "        \"scales\": y_scales,\n",
        "        \"opacities\": y_opacities,\n",
        "        \"colors\": y_colors,\n",
        "    }\n",
        "    return y\n",
        "\n",
        "\n",
        "def default_forward(model, image):\n",
        "    x = TENSOR_TRANSFORM(image)\n",
        "    y = model.encoder(x)\n",
        "    return y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "N_CLASSES = 10\n",
        "N_SAMPLES = 1\n",
        "MODEL_PATH = \"../models/final_models/conv_method_3\"  # TODO: Change path\n",
        "CUSTOM_MEANS_MODEL = torch.load(f\"{MODEL_PATH}/means_model.pt\", map_location=DEVICE)\n",
        "CUSTOM_QUATS_MODEL = torch.load(f\"{MODEL_PATH}/quats_model.pt\", map_location=DEVICE)\n",
        "CUSTOM_SCALES_MODEL = torch.load(f\"{MODEL_PATH}/scales_model.pt\", map_location=DEVICE)\n",
        "CUSTOM_OPACITIES_MODEL = torch.load(\n",
        "    f\"{MODEL_PATH}/opacities_model.pt\", map_location=DEVICE\n",
        ")\n",
        "CUSTOM_COLORS_MODEL = torch.load(f\"{MODEL_PATH}/colors_model.pt\", map_location=DEVICE)\n",
        "\n",
        "DEFAULT_MODEL = DefaultResNetAutoencoder(\"light\")\n",
        "DEFAULT_MODEL.load_state_dict(\n",
        "    torch.load(\"../models/default_resnet_autoencoder.ckpt\")[\"model_state_dict\"]\n",
        ")\n",
        "\n",
        "test_dataset = CIFAR10GaussianSplatsDataset(\n",
        "    root=\"../data/CIFAR10GS\",  # TODO: Change path\n",
        "    test=True,\n",
        "    init_type=\"grid\",\n",
        ")\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size=1,\n",
        "    shuffle=False,\n",
        "    collate_fn=noop_collate,\n",
        ")\n",
        "\n",
        "CLASS_TO_INDEX = test_dataset.class_to_index\n",
        "INDEX_TO_CLASS = {v: k for k, v in CLASS_TO_INDEX.items()}\n",
        "DATA = collect_samples_by_label(\n",
        "    test_dataset, N_SAMPLES, test_loader, CLASS_TO_INDEX, INDEX_TO_CLASS\n",
        ")\n",
        "CUSTOM_RESULTS = {k: [] for k in CLASS_TO_INDEX.keys()}\n",
        "DEFAULT_RESULTS = {k: [] for k in CLASS_TO_INDEX.keys()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "for label, samples in DATA.items():\n",
        "    for image, splat in samples:\n",
        "        if (\n",
        "            CUSTOM_MEANS_MODEL\n",
        "            and CUSTOM_QUATS_MODEL\n",
        "            and CUSTOM_SCALES_MODEL\n",
        "            and CUSTOM_OPACITIES_MODEL\n",
        "            and CUSTOM_COLORS_MODEL\n",
        "        ):\n",
        "            CUSTOM_RESULTS[label].append(\n",
        "                custom_forward(\n",
        "                    CUSTOM_MEANS_MODEL,\n",
        "                    CUSTOM_QUATS_MODEL,\n",
        "                    CUSTOM_SCALES_MODEL,\n",
        "                    CUSTOM_OPACITIES_MODEL,\n",
        "                    CUSTOM_COLORS_MODEL,\n",
        "                    splat,\n",
        "                )\n",
        "            )\n",
        "        if DEFAULT_MODEL:\n",
        "            DEFAULT_RESULTS[label].append(default_forward(DEFAULT_MODEL, image))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Label: airplane, Sample: 0, Default: 0.75, Custom: 1.5\n",
            "Label: automobile, Sample: 0, Default: 0.75, Custom: 1.5\n",
            "Label: bird, Sample: 0, Default: 0.75, Custom: 1.5\n",
            "Label: cat, Sample: 0, Default: 0.75, Custom: 1.5\n",
            "Label: deer, Sample: 0, Default: 0.75, Custom: 1.5\n",
            "Label: dog, Sample: 0, Default: 0.75, Custom: 1.5\n",
            "Label: frog, Sample: 0, Default: 0.75, Custom: 1.5\n",
            "Label: horse, Sample: 0, Default: 0.75, Custom: 1.5\n",
            "Label: ship, Sample: 0, Default: 0.75, Custom: 1.5\n",
            "Label: truck, Sample: 0, Default: 0.75, Custom: 1.5\n"
          ]
        }
      ],
      "source": [
        "for label, samples in DATA.items():\n",
        "    for i, (image, splat) in enumerate(samples):\n",
        "        default_compression_ratio = compression_ratio(image, DEFAULT_RESULTS[label][i])\n",
        "        custom_means_compression_ratio = compression_ratio(\n",
        "            image, CUSTOM_RESULTS[label][i][\"means\"]\n",
        "        )\n",
        "        custom_quats_compression_ratio = compression_ratio(\n",
        "            image, CUSTOM_RESULTS[label][i][\"quats\"]\n",
        "        )\n",
        "        custom_scales_compression_ratio = compression_ratio(\n",
        "            image, CUSTOM_RESULTS[label][i][\"scales\"]\n",
        "        )\n",
        "        custom_opacities_compression_ratio = compression_ratio(\n",
        "            image, CUSTOM_RESULTS[label][i][\"opacities\"]\n",
        "        )\n",
        "        custom_colors_compression_ratio = compression_ratio(\n",
        "            image, CUSTOM_RESULTS[label][i][\"colors\"]\n",
        "        )\n",
        "        custom_compression_ratio = (\n",
        "            custom_means_compression_ratio\n",
        "            + custom_quats_compression_ratio\n",
        "            + custom_scales_compression_ratio\n",
        "            + custom_opacities_compression_ratio\n",
        "            + custom_colors_compression_ratio\n",
        "        )\n",
        "        print(\n",
        "            f\"Label: {label}, Sample: {i}, Default: {default_compression_ratio}, Custom: {custom_compression_ratio}\"\n",
        "        )"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
