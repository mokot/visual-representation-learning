{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Note: This is a hack to allow importing from the parent directory\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "sys.path.append(str(Path().resolve().parent))\n",
        "sys.path.append(str(Path().resolve().parent / \"submodules/resnet-18-autoencoder/src\"))\n",
        "\n",
        "# Note: Ignore warnings, be brave (YoLo)\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from data import CIFAR10GaussianSplatsDataset\n",
        "from utils import noop_collate, transform_autoencoder_input, transform_autoencoder_output\n",
        "\n",
        "plt.style.use(\"../style/main.mpltstyle\")\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "def collect_samples_by_label(data, n_samples, test_loader, class_to_index, index_to_class):\n",
        "    data = {k: [] for k in class_to_index.keys()}\n",
        "    all_labels_filled = False  \n",
        "\n",
        "    for batch in test_loader:\n",
        "        if all_labels_filled:\n",
        "            break  \n",
        "\n",
        "        for image, index, splat in batch:\n",
        "            label = index_to_class[index]\n",
        "            if len(data[label]) < n_samples:\n",
        "                data[label].append((image, splat))\n",
        "\n",
        "            all_labels_filled = all(len(v) >= n_samples for v in data.values())\n",
        "            if all_labels_filled:\n",
        "                break  \n",
        "            \n",
        "    return data\n",
        "\n",
        "\n",
        "def custom_forward(means_model, quats_model, scales_model, opacities_model, colors_model, splat):\n",
        "    means_model = means_model.to(DEVICE)\n",
        "    quats_model = quats_model.to(DEVICE)\n",
        "    scales_model = scales_model.to(DEVICE)\n",
        "    opacities_model = opacities_model.to(DEVICE)\n",
        "    colors_model = colors_model.to(DEVICE)\n",
        "    splat = splat.to(DEVICE)\n",
        "    x = transform_autoencoder_input(splat, \"dict\")\n",
        "    x_means = x[\"means\"].unsqueeze(0)\n",
        "    x_quats = x[\"quats\"].unsqueeze(0)\n",
        "    x_scales = x[\"scales\"].unsqueeze(0)\n",
        "    x_opacities = x[\"opacities\"].unsqueeze(0)\n",
        "    x_colors = x[\"colors\"].unsqueeze(0)\n",
        "    y_means = means_model(x_means).squeeze(0)\n",
        "    y_quats = quats_model(x_quats).squeeze(0)\n",
        "    y_scales = scales_model(x_scales).squeeze(0)\n",
        "    y_opacities = opacities_model(x_opacities).squeeze(0)\n",
        "    y_colors = colors_model(x_colors).squeeze(0)\n",
        "    y = {\n",
        "        \"means\": y_means,\n",
        "        \"quats\": y_quats,\n",
        "        \"scales\": y_scales,\n",
        "        \"opacities\": y_opacities,\n",
        "        \"colors\": y_colors,\n",
        "    }\n",
        "    splat = transform_autoencoder_output(y, \"dict\")\n",
        "    return splat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "N_CLASSES = 10  \n",
        "N_SAMPLES = 1\n",
        "MODEL_PATH = \"../models/final_models/conv_method_3\" \n",
        "CUSTOM_MEANS_MODEL = torch.load(f\"{MODEL_PATH}/means_model.pt\", map_location=DEVICE)\n",
        "CUSTOM_QUATS_MODEL = torch.load(f\"{MODEL_PATH}/quats_model.pt\", map_location=DEVICE)\n",
        "CUSTOM_SCALES_MODEL = torch.load(f\"{MODEL_PATH}/scales_model.pt\", map_location=DEVICE)\n",
        "CUSTOM_OPACITIES_MODEL = torch.load(f\"{MODEL_PATH}/opacities_model.pt\", map_location=DEVICE)\n",
        "CUSTOM_COLORS_MODEL = torch.load(f\"{MODEL_PATH}/colors_model.pt\", map_location=DEVICE)\n",
        "\n",
        "test_dataset = CIFAR10GaussianSplatsDataset(\n",
        "    root=\"../data/CIFAR10GS\", \n",
        "    test=True,\n",
        "    init_type=\"grid\",\n",
        ")\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size=1,\n",
        "    shuffle=False,\n",
        "    collate_fn=noop_collate,\n",
        ")\n",
        "\n",
        "CLASS_TO_INDEX = test_dataset.class_to_index\n",
        "INDEX_TO_CLASS = {v: k for k, v in CLASS_TO_INDEX.items()}\n",
        "DATA = collect_samples_by_label(test_dataset, N_SAMPLES, test_loader, CLASS_TO_INDEX, INDEX_TO_CLASS)\n",
        "CUSTOM_RESULTS = {k: [] for k in CLASS_TO_INDEX.keys()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Label: airplane\n",
            "colors: [-9.533025741577148, 12.163064002990723] -> [-0.9641077518463135, 0.8002510666847229]\n",
            "means: [-1.0, 1.0] -> [-0.9979274272918701, 0.9987775087356567]\n",
            "opacities: [-4.73273229598999, 5.293581008911133] -> [-0.9243193864822388, 0.835913360118866]\n",
            "quats: [-1.6623637676239014, 2.6217942237854004] -> [-0.5537052750587463, 0.5027226805686951]\n",
            "scales: [-10.672653198242188, 3.9764418601989746] -> [-0.9996795654296875, 1.0]\n",
            "===\n",
            "Label: automobile\n",
            "colors: [-10.232390403747559, 11.857702255249023] -> [-0.9708322286605835, 0.8739020228385925]\n",
            "means: [-1.0, 1.0] -> [-0.9979274272918701, 0.9987775087356567]\n",
            "opacities: [-4.8982954025268555, 5.20357608795166] -> [-0.9029794335365295, 0.8699905872344971]\n",
            "quats: [-1.4995923042297363, 2.910125494003296] -> [-0.6938697099685669, 0.5712622404098511]\n",
            "scales: [-11.359330177307129, 4.201854705810547] -> [-0.9996407628059387, 1.0]\n",
            "===\n",
            "Label: bird\n",
            "colors: [-7.313357830047607, 8.84171199798584] -> [-0.9591242671012878, 0.816911518573761]\n",
            "means: [-1.0, 1.0] -> [-0.9979274272918701, 0.9987775087356567]\n",
            "opacities: [-4.565436840057373, 4.05141544342041] -> [-0.9548801779747009, 0.841410219669342]\n",
            "quats: [-1.2440365552902222, 3.366917848587036] -> [-0.6586707830429077, 0.5613754391670227]\n",
            "scales: [-8.187206268310547, 3.7512669563293457] -> [-0.9995256662368774, 1.0]\n",
            "===\n",
            "Label: cat\n",
            "colors: [-11.481281280517578, 13.023453712463379] -> [-0.9658380746841431, 0.6998340487480164]\n",
            "means: [-1.0, 1.0] -> [-0.9979274272918701, 0.9987775087356567]\n",
            "opacities: [-4.612491130828857, 4.653690814971924] -> [-0.9328785538673401, 0.9601823687553406]\n",
            "quats: [-1.3467092514038086, 2.8560562133789062] -> [-0.651943027973175, 0.5166469216346741]\n",
            "scales: [-10.90050220489502, 4.688673496246338] -> [-0.999534010887146, 1.0]\n",
            "===\n",
            "Label: deer\n",
            "colors: [-11.698781967163086, 13.803009986877441] -> [-0.9683241844177246, 0.8216938972473145]\n",
            "means: [-1.0, 1.0] -> [-0.9979274272918701, 0.9987775087356567]\n",
            "opacities: [-4.890936374664307, 4.803365707397461] -> [-0.9120721817016602, 0.907353937625885]\n",
            "quats: [-2.166600227355957, 2.5040700435638428] -> [-0.5786547064781189, 0.6640697121620178]\n",
            "scales: [-10.221508979797363, 3.7017502784729004] -> [-0.9996650218963623, 1.0]\n",
            "===\n",
            "Label: dog\n",
            "colors: [-11.630428314208984, 13.563864707946777] -> [-0.9637771248817444, 0.6805310249328613]\n",
            "means: [-1.0, 1.0] -> [-0.9979274272918701, 0.9987775087356567]\n",
            "opacities: [-4.836583137512207, 5.109440803527832] -> [-0.9226751923561096, 0.8795185089111328]\n",
            "quats: [-1.4494799375534058, 2.961209297180176] -> [-0.6598955392837524, 0.586963415145874]\n",
            "scales: [-8.484810829162598, 3.4842867851257324] -> [-0.9995365738868713, 1.0]\n",
            "===\n",
            "Label: frog\n",
            "colors: [-9.077479362487793, 11.023773193359375] -> [-0.9703987240791321, 0.8930346369743347]\n",
            "means: [-1.0, 1.0] -> [-0.9979274272918701, 0.9987775087356567]\n",
            "opacities: [-4.745082855224609, 5.133230686187744] -> [-0.9242200255393982, 0.9651732444763184]\n",
            "quats: [-1.3585455417633057, 3.601199150085449] -> [-0.6781280040740967, 0.5580016374588013]\n",
            "scales: [-8.516214370727539, 3.759931802749634] -> [-0.9996440410614014, 1.0]\n",
            "===\n",
            "Label: horse\n",
            "colors: [-9.300802230834961, 12.217658996582031] -> [-0.9712315797805786, 0.8457219004631042]\n",
            "means: [-1.0, 1.0] -> [-0.9979274272918701, 0.9987775087356567]\n",
            "opacities: [-4.920316696166992, 4.329853534698486] -> [-0.8929834365844727, 0.8470284938812256]\n",
            "quats: [-1.1897882223129272, 2.364327907562256] -> [-0.594169020652771, 0.5563682317733765]\n",
            "scales: [-8.143842697143555, 3.7462081909179688] -> [-0.999830424785614, 1.0]\n",
            "===\n",
            "Label: ship\n",
            "colors: [-9.046455383300781, 10.8825101852417] -> [-0.9741515517234802, 0.7905954122543335]\n",
            "means: [-1.0, 1.0] -> [-0.9979274272918701, 0.9987775087356567]\n",
            "opacities: [-4.792640686035156, 5.121659278869629] -> [-0.9134075045585632, 0.8331432938575745]\n",
            "quats: [-1.4303817749023438, 2.8786020278930664] -> [-0.66522216796875, 0.6044134497642517]\n",
            "scales: [-9.78883171081543, 4.572704315185547] -> [-0.9996569156646729, 1.0]\n",
            "===\n",
            "Label: truck\n",
            "colors: [-9.640141487121582, 11.17776870727539] -> [-0.9712401628494263, 0.8434150815010071]\n",
            "means: [-1.0, 1.0] -> [-0.9979274272918701, 0.9987775087356567]\n",
            "opacities: [-4.65819787979126, 4.557453155517578] -> [-0.955782949924469, 0.9385344982147217]\n",
            "quats: [-1.429076910018921, 3.4939022064208984] -> [-0.7100047469139099, 0.541629433631897]\n",
            "scales: [-10.177995681762695, 4.081628322601318] -> [-0.9997687935829163, 1.0]\n",
            "===\n"
          ]
        }
      ],
      "source": [
        "for label, samples in DATA.items():\n",
        "    print(f\"Label: {label}\")\n",
        "    for image, splat in samples:\n",
        "        result = custom_forward(CUSTOM_MEANS_MODEL, CUSTOM_QUATS_MODEL, CUSTOM_SCALES_MODEL, CUSTOM_OPACITIES_MODEL, CUSTOM_COLORS_MODEL, splat)\n",
        "        for param, value in result.items():\n",
        "            if param == \"Ks\" or param == \"viewmats\":\n",
        "                continue\n",
        "            print(f\"{param}: [{splat[param].min()}, {splat[param].max()}] -> [{result[param].min()}, {result[param].max()}]\")\n",
        "    print(\"===\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'means': {'min': -1.0, 'max': 1.0},\n",
              " 'quats': {'min': -3.7537035942077637, 'max': 4.574342727661133},\n",
              " 'scales': {'min': -14.256706237792969, 'max': 6.657063961029053},\n",
              " 'opacities': {'min': -5.512201309204102, 'max': 7.002721309661865},\n",
              " 'colors': {'min': -15.537788391113281, 'max': 17.288856506347656}}"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_dataset = CIFAR10GaussianSplatsDataset(\n",
        "    root=\"../data/CIFAR10GS\",\n",
        "    train=True,\n",
        "    init_type=\"grid\",\n",
        ")\n",
        "val_dataset = CIFAR10GaussianSplatsDataset(\n",
        "    root=\"../data/CIFAR10GS\",\n",
        "    val=True,\n",
        "    init_type=\"grid\",\n",
        ")\n",
        "dataset = torch.utils.data.ConcatDataset([train_dataset, val_dataset])\n",
        "dataloader = torch.utils.data.DataLoader(\n",
        "    dataset,\n",
        "    batch_size=1,\n",
        "    shuffle=False,\n",
        "    collate_fn=noop_collate,\n",
        ")\n",
        "\n",
        "\n",
        "TEMP_SPLAT_RANGES = {\n",
        "    \"means\": {\"min\": [], \"max\": []},\n",
        "    \"quats\": {\"min\": [], \"max\": []},\n",
        "    \"scales\": {\"min\": [], \"max\": []},\n",
        "    \"opacities\": {\"min\": [], \"max\": []},\n",
        "    \"colors\": {\"min\": [], \"max\": []},\n",
        "}\n",
        "\n",
        "# Loop though all samples and find min and max for each splat parameter\n",
        "for batch in dataloader:\n",
        "    for image, index, splat in batch:\n",
        "        label = INDEX_TO_CLASS[index]\n",
        "        for param, value in splat.items():\n",
        "            if param == \"Ks\" or param == \"viewmats\":\n",
        "                continue\n",
        "            TEMP_SPLAT_RANGES[param][\"min\"].append(value.min())\n",
        "            TEMP_SPLAT_RANGES[param][\"max\"].append(value.max())\n",
        "\n",
        "SPLAT_RANGES = {\n",
        "    \"means\": {\"min\": min(TEMP_SPLAT_RANGES[\"means\"][\"min\"]).item(), \"max\": max(TEMP_SPLAT_RANGES[\"means\"][\"max\"]).item()},\n",
        "    \"quats\": {\"min\": min(TEMP_SPLAT_RANGES[\"quats\"][\"min\"]).item(), \"max\": max(TEMP_SPLAT_RANGES[\"quats\"][\"max\"]).item()},\n",
        "    \"scales\": {\"min\": min(TEMP_SPLAT_RANGES[\"scales\"][\"min\"]).item(), \"max\": max(TEMP_SPLAT_RANGES[\"scales\"][\"max\"]).item()},\n",
        "    \"opacities\": {\"min\": min(TEMP_SPLAT_RANGES[\"opacities\"][\"min\"]).item(), \"max\": max(TEMP_SPLAT_RANGES[\"opacities\"][\"max\"]).item()},\n",
        "    \"colors\": {\"min\": min(TEMP_SPLAT_RANGES[\"colors\"][\"min\"]).item(), \"max\": max(TEMP_SPLAT_RANGES[\"colors\"][\"max\"]).item()},\n",
        "}\n",
        "SPLAT_RANGES"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
