{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Note: This is a hack to allow importing from the parent directory\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "sys.path.append(str(Path().resolve().parent))\n",
        "sys.path.append(str(Path().resolve().parent / \"submodules/resnet-18-autoencoder/src\"))\n",
        "\n",
        "# Note: Ignore warnings, be brave (YoLo)\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from data import CIFAR10GaussianSplatsDataset\n",
        "from utils import (\n",
        "    noop_collate,\n",
        "    transform_autoencoder_input,\n",
        "    transform_autoencoder_output,\n",
        ")\n",
        "\n",
        "plt.style.use(\"../style/main.mpltstyle\")\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "def collect_samples_by_label(\n",
        "    data, n_samples, test_loader, class_to_index, index_to_class\n",
        "):\n",
        "    data = {k: [] for k in class_to_index.keys()}\n",
        "    all_labels_filled = False\n",
        "\n",
        "    for batch in test_loader:\n",
        "        if all_labels_filled:\n",
        "            break\n",
        "\n",
        "        for image, index, splat in batch:\n",
        "            label = index_to_class[index]\n",
        "            if len(data[label]) < n_samples:\n",
        "                data[label].append((image, splat))\n",
        "\n",
        "            all_labels_filled = all(len(v) >= n_samples for v in data.values())\n",
        "            if all_labels_filled:\n",
        "                break\n",
        "\n",
        "    return data\n",
        "\n",
        "\n",
        "def custom_forward(\n",
        "    means_model, quats_model, scales_model, opacities_model, colors_model, splat\n",
        "):\n",
        "    means_model = means_model.to(DEVICE)\n",
        "    quats_model = quats_model.to(DEVICE)\n",
        "    scales_model = scales_model.to(DEVICE)\n",
        "    opacities_model = opacities_model.to(DEVICE)\n",
        "    colors_model = colors_model.to(DEVICE)\n",
        "    splat = splat.to(DEVICE)\n",
        "    x = transform_autoencoder_input(splat, \"dict\")\n",
        "    x_means = x[\"means\"].unsqueeze(0)\n",
        "    x_quats = x[\"quats\"].unsqueeze(0)\n",
        "    x_scales = x[\"scales\"].unsqueeze(0)\n",
        "    x_opacities = x[\"opacities\"].unsqueeze(0)\n",
        "    x_colors = x[\"colors\"].unsqueeze(0)\n",
        "    y_means = means_model(x_means).squeeze(0)\n",
        "    y_quats = quats_model(x_quats).squeeze(0)\n",
        "    y_scales = scales_model(x_scales).squeeze(0)\n",
        "    y_opacities = opacities_model(x_opacities).squeeze(0)\n",
        "    y_colors = colors_model(x_colors).squeeze(0)\n",
        "    y = {\n",
        "        \"means\": y_means,\n",
        "        \"quats\": y_quats,\n",
        "        \"scales\": y_scales,\n",
        "        \"opacities\": y_opacities,\n",
        "        \"colors\": y_colors,\n",
        "    }\n",
        "    splat = transform_autoencoder_output(y, \"dict\")\n",
        "    return splat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "N_CLASSES = 10\n",
        "N_SAMPLES = 1\n",
        "MODEL_PATH = \"../models/final_models/conv_method_3\"\n",
        "CUSTOM_MEANS_MODEL = torch.load(f\"{MODEL_PATH}/means_model.pt\", map_location=DEVICE)\n",
        "CUSTOM_QUATS_MODEL = torch.load(f\"{MODEL_PATH}/quats_model.pt\", map_location=DEVICE)\n",
        "CUSTOM_SCALES_MODEL = torch.load(f\"{MODEL_PATH}/scales_model.pt\", map_location=DEVICE)\n",
        "CUSTOM_OPACITIES_MODEL = torch.load(\n",
        "    f\"{MODEL_PATH}/opacities_model.pt\", map_location=DEVICE\n",
        ")\n",
        "CUSTOM_COLORS_MODEL = torch.load(f\"{MODEL_PATH}/colors_model.pt\", map_location=DEVICE)\n",
        "\n",
        "test_dataset = CIFAR10GaussianSplatsDataset(\n",
        "    root=\"../data/CIFAR10GS\",\n",
        "    test=True,\n",
        "    init_type=\"grid\",\n",
        ")\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size=1,\n",
        "    shuffle=False,\n",
        "    collate_fn=noop_collate,\n",
        ")\n",
        "\n",
        "CLASS_TO_INDEX = test_dataset.class_to_index\n",
        "INDEX_TO_CLASS = {v: k for k, v in CLASS_TO_INDEX.items()}\n",
        "DATA = collect_samples_by_label(\n",
        "    test_dataset, N_SAMPLES, test_loader, CLASS_TO_INDEX, INDEX_TO_CLASS\n",
        ")\n",
        "CUSTOM_RESULTS = {k: [] for k in CLASS_TO_INDEX.keys()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Label: airplane\n"
          ]
        },
        {
          "ename": "TypeError",
          "evalue": "unsupported operand type(s) for -: 'Tensor' and 'list'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[5], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLabel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabel\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m image, splat \u001b[38;5;129;01min\u001b[39;00m samples:\n\u001b[0;32m----> 4\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mcustom_forward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m        \u001b[49m\u001b[43mCUSTOM_MEANS_MODEL\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m        \u001b[49m\u001b[43mCUSTOM_QUATS_MODEL\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m        \u001b[49m\u001b[43mCUSTOM_SCALES_MODEL\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m        \u001b[49m\u001b[43mCUSTOM_OPACITIES_MODEL\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m        \u001b[49m\u001b[43mCUSTOM_COLORS_MODEL\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplat\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m param, value \u001b[38;5;129;01min\u001b[39;00m result\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m     13\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m param \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mKs\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m param \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mviewmats\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
            "Cell \u001b[0;32mIn[3], line 32\u001b[0m, in \u001b[0;36mcustom_forward\u001b[0;34m(means_model, quats_model, scales_model, opacities_model, colors_model, splat)\u001b[0m\n\u001b[1;32m     30\u001b[0m colors_model \u001b[38;5;241m=\u001b[39m colors_model\u001b[38;5;241m.\u001b[39mto(DEVICE)\n\u001b[1;32m     31\u001b[0m splat \u001b[38;5;241m=\u001b[39m splat\u001b[38;5;241m.\u001b[39mto(DEVICE)\n\u001b[0;32m---> 32\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mtransform_autoencoder_input\u001b[49m\u001b[43m(\u001b[49m\u001b[43msplat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m x_means \u001b[38;5;241m=\u001b[39m x[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmeans\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     34\u001b[0m x_quats \u001b[38;5;241m=\u001b[39m x[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquats\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\n",
            "File \u001b[0;32m~/LMU/VisualRepresentationLearning/Project/utils/data.py:197\u001b[0m, in \u001b[0;36mtransform_autoencoder_input\u001b[0;34m(parameter_dict, join_mode)\u001b[0m\n\u001b[1;32m    192\u001b[0m colors \u001b[38;5;241m=\u001b[39m parameter_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolors\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mclone()\u001b[38;5;241m.\u001b[39mdetach()  \u001b[38;5;66;03m# 1024x4x3\u001b[39;00m\n\u001b[1;32m    193\u001b[0m \u001b[38;5;66;03m# Ks = parameter_dict[\"Ks\"].clone().detach()  # 3x3\u001b[39;00m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;66;03m# viewmats = parameter_dict[\"viewmats\"].clone().detach()  # 4x4\u001b[39;00m\n\u001b[1;32m    195\u001b[0m \n\u001b[1;32m    196\u001b[0m \u001b[38;5;66;03m# Normalize the input to the range [-1, 1]\u001b[39;00m\n\u001b[0;32m--> 197\u001b[0m means \u001b[38;5;241m=\u001b[39m \u001b[43mnormalize_to_neg_one_one\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmeans\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCIFAR10_GRID_RANGES\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmeans\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmean\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCIFAR10_GRID_RANGES\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmeans\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstd\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    200\u001b[0m quats \u001b[38;5;241m=\u001b[39m normalize_to_neg_one_one(\n\u001b[1;32m    201\u001b[0m     quats, CIFAR10_GRID_RANGES[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquats\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m\"\u001b[39m], CIFAR10_GRID_RANGES[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquats\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstd\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    202\u001b[0m )\n\u001b[1;32m    203\u001b[0m scales \u001b[38;5;241m=\u001b[39m normalize_to_neg_one_one(\n\u001b[1;32m    204\u001b[0m     scales,\n\u001b[1;32m    205\u001b[0m     CIFAR10_GRID_RANGES[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscales\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m    206\u001b[0m     CIFAR10_GRID_RANGES[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscales\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstd\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m    207\u001b[0m )\n",
            "File \u001b[0;32m~/LMU/VisualRepresentationLearning/Project/utils/normalization.py:19\u001b[0m, in \u001b[0;36mnormalize_to_neg_one_one\u001b[0;34m(x, mean, std)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;124;03mNormalizes the input tensor `x` to the range [-1, 1] using the provided mean and std.\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;124;03mtorch.Tensor: The normalized tensor in the range [-1, 1].\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     18\u001b[0m std[std \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m  \u001b[38;5;66;03m# Avoid division by zero\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m x \u001b[38;5;241m=\u001b[39m (\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmean\u001b[49m) \u001b[38;5;241m/\u001b[39m std  \u001b[38;5;66;03m# Standardization\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mtanh(x)\n",
            "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for -: 'Tensor' and 'list'"
          ]
        }
      ],
      "source": [
        "for label, samples in DATA.items():\n",
        "    print(f\"Label: {label}\")\n",
        "    for image, splat in samples:\n",
        "        result = custom_forward(\n",
        "            CUSTOM_MEANS_MODEL,\n",
        "            CUSTOM_QUATS_MODEL,\n",
        "            CUSTOM_SCALES_MODEL,\n",
        "            CUSTOM_OPACITIES_MODEL,\n",
        "            CUSTOM_COLORS_MODEL,\n",
        "            splat,\n",
        "        )\n",
        "        for param, value in result.items():\n",
        "            if param == \"Ks\" or param == \"viewmats\":\n",
        "                continue\n",
        "            print(\n",
        "                f\"{param}: [{splat[param].min()}, {splat[param].max()}] -> [{result[param].min()}, {result[param].max()}]\"\n",
        "            )\n",
        "    print(\"===\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'means': {'min': -1.0,\n",
              "  'max': 1.0,\n",
              "  'mean': [3.073364496231079e-08, 0.0, 0.0],\n",
              "  'std': [0.5956833958625793, 0.5956833958625793, 0.0]},\n",
              " 'quats': {'min': -3.7537035942077637,\n",
              "  'max': 4.574342727661133,\n",
              "  'mean': [0.49086257815361023,\n",
              "   0.5112597346305847,\n",
              "   0.49628859758377075,\n",
              "   0.48551133275032043],\n",
              "  'std': [0.4739896357059479,\n",
              "   0.5310168266296387,\n",
              "   0.5126069188117981,\n",
              "   0.4742636978626251]},\n",
              " 'scales': {'min': -14.256706237792969,\n",
              "  'max': 6.657063961029053,\n",
              "  'mean': [-1.8529794216156006, -1.8229098320007324, -2.4987568855285645],\n",
              "  'std': [1.4585336446762085, 1.509230375289917, 0.5868567228317261]},\n",
              " 'opacities': {'min': -5.512201309204102,\n",
              "  'max': 7.002721309661865,\n",
              "  'mean': -3.367799997329712,\n",
              "  'std': 1.417393684387207},\n",
              " 'colors': {'min': -15.537788391113281,\n",
              "  'max': 17.288856506347656,\n",
              "  'mean': [[0.6861101388931274, 0.6411524415016174, 0.6533592343330383],\n",
              "   [-0.034583691507577896, -0.02748388983309269, -0.015395736321806908],\n",
              "   [0.7585484981536865, 0.7298418879508972, 0.6634648442268372],\n",
              "   [-0.01002707239240408, -0.020831072703003883, -0.022523043677210808]],\n",
              "  'std': [[2.45888614654541, 2.381861686706543, 2.402751922607422],\n",
              "   [1.9165422916412354, 1.8433748483657837, 1.8344460725784302],\n",
              "   [2.15236496925354, 2.076561689376831, 2.0886363983154297],\n",
              "   [1.91488516330719, 1.835733413696289, 1.827427864074707]]}}"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_dataset = CIFAR10GaussianSplatsDataset(\n",
        "    root=\"../data/CIFAR10GS\",\n",
        "    train=True,\n",
        "    init_type=\"grid\",\n",
        ")\n",
        "val_dataset = CIFAR10GaussianSplatsDataset(\n",
        "    root=\"../data/CIFAR10GS\",\n",
        "    val=True,\n",
        "    init_type=\"grid\",\n",
        ")\n",
        "dataset = torch.utils.data.ConcatDataset([train_dataset, val_dataset])\n",
        "dataloader = torch.utils.data.DataLoader(\n",
        "    dataset,\n",
        "    batch_size=1,\n",
        "    shuffle=False,\n",
        "    collate_fn=noop_collate,\n",
        ")\n",
        "\n",
        "\n",
        "TEMP_SPLAT_RANGES = {\n",
        "    \"means\": {\"min\": [], \"max\": [], \"mean\": [], \"std\": []},\n",
        "    \"quats\": {\"min\": [], \"max\": [], \"mean\": [], \"std\": []},\n",
        "    \"scales\": {\"min\": [], \"max\": [], \"mean\": [], \"std\": []},\n",
        "    \"opacities\": {\"min\": [], \"max\": [], \"mean\": [], \"std\": []},\n",
        "    \"colors\": {\"min\": [], \"max\": [], \"mean\": [], \"std\": []},\n",
        "}\n",
        "\n",
        "# Loop though all samples and find min and max for each splat parameter\n",
        "for batch in dataloader:\n",
        "    for image, index, splat in batch:\n",
        "        label = INDEX_TO_CLASS[index]\n",
        "        for param, value in splat.items():\n",
        "            if param == \"Ks\" or param == \"viewmats\":\n",
        "                continue\n",
        "            TEMP_SPLAT_RANGES[param][\"min\"].append(value.min())\n",
        "            TEMP_SPLAT_RANGES[param][\"max\"].append(value.max())\n",
        "            TEMP_SPLAT_RANGES[param][\"mean\"].append(value)\n",
        "            TEMP_SPLAT_RANGES[param][\"std\"].append(value)\n",
        "\n",
        "SPLAT_RANGES = {\n",
        "    \"means\": {\n",
        "        \"min\": min(TEMP_SPLAT_RANGES[\"means\"][\"min\"]).item(),\n",
        "        \"max\": max(TEMP_SPLAT_RANGES[\"means\"][\"max\"]).item(),\n",
        "        \"mean\": torch.stack(TEMP_SPLAT_RANGES[\"means\"][\"mean\"])\n",
        "        .mean(dim=(0, 1))\n",
        "        .tolist(),\n",
        "        \"std\": torch.stack(TEMP_SPLAT_RANGES[\"means\"][\"std\"]).std(dim=(0, 1)).tolist(),\n",
        "    },\n",
        "    \"quats\": {\n",
        "        \"min\": min(TEMP_SPLAT_RANGES[\"quats\"][\"min\"]).item(),\n",
        "        \"max\": max(TEMP_SPLAT_RANGES[\"quats\"][\"max\"]).item(),\n",
        "        \"mean\": torch.stack(TEMP_SPLAT_RANGES[\"quats\"][\"mean\"])\n",
        "        .mean(dim=(0, 1))\n",
        "        .tolist(),\n",
        "        \"std\": torch.stack(TEMP_SPLAT_RANGES[\"quats\"][\"std\"]).std(dim=(0, 1)).tolist(),\n",
        "    },\n",
        "    \"scales\": {\n",
        "        \"min\": min(TEMP_SPLAT_RANGES[\"scales\"][\"min\"]).item(),\n",
        "        \"max\": max(TEMP_SPLAT_RANGES[\"scales\"][\"max\"]).item(),\n",
        "        \"mean\": torch.stack(TEMP_SPLAT_RANGES[\"scales\"][\"mean\"])\n",
        "        .mean(dim=(0, 1))\n",
        "        .tolist(),\n",
        "        \"std\": torch.stack(TEMP_SPLAT_RANGES[\"scales\"][\"std\"]).std(dim=(0, 1)).tolist(),\n",
        "    },\n",
        "    \"opacities\": {\n",
        "        \"min\": min(TEMP_SPLAT_RANGES[\"opacities\"][\"min\"]).item(),\n",
        "        \"max\": max(TEMP_SPLAT_RANGES[\"opacities\"][\"max\"]).item(),\n",
        "        \"mean\": torch.stack(TEMP_SPLAT_RANGES[\"opacities\"][\"mean\"])\n",
        "        .mean(dim=(0, 1))\n",
        "        .tolist(),\n",
        "        \"std\": torch.stack(TEMP_SPLAT_RANGES[\"opacities\"][\"std\"])\n",
        "        .std(dim=(0, 1))\n",
        "        .tolist(),\n",
        "    },\n",
        "    \"colors\": {\n",
        "        \"min\": min(TEMP_SPLAT_RANGES[\"colors\"][\"min\"]).item(),\n",
        "        \"max\": max(TEMP_SPLAT_RANGES[\"colors\"][\"max\"]).item(),\n",
        "        \"mean\": torch.stack(TEMP_SPLAT_RANGES[\"colors\"][\"mean\"])\n",
        "        .mean(dim=(0, 1))\n",
        "        .tolist(),\n",
        "        \"std\": torch.stack(TEMP_SPLAT_RANGES[\"colors\"][\"std\"]).std(dim=(0, 1)).tolist(),\n",
        "    },\n",
        "}\n",
        "SPLAT_RANGES"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'means': {'min': -1.0,\n",
              "  'max': 1.0,\n",
              "  'mean': tensor([3.0734e-08, 0.0000e+00, 0.0000e+00]),\n",
              "  'std': tensor([0.5957, 0.5957, 0.0000])},\n",
              " 'quats': {'min': -3.7537035942077637,\n",
              "  'max': 4.574342727661133,\n",
              "  'mean': tensor([0.4909, 0.5113, 0.4963, 0.4855]),\n",
              "  'std': tensor([0.4740, 0.5310, 0.5126, 0.4743])},\n",
              " 'scales': {'min': -14.256706237792969,\n",
              "  'max': 6.657063961029053,\n",
              "  'mean': tensor([-1.8530, -1.8229, -2.4988]),\n",
              "  'std': tensor([1.4585, 1.5092, 0.5869])},\n",
              " 'opacities': {'min': -5.512201309204102,\n",
              "  'max': 7.002721309661865,\n",
              "  'mean': tensor(-3.3678),\n",
              "  'std': tensor(1.4174)},\n",
              " 'colors': {'min': -15.537788391113281,\n",
              "  'max': 17.288856506347656,\n",
              "  'mean': tensor([[ 0.6861,  0.6412,  0.6534],\n",
              "          [-0.0346, -0.0275, -0.0154],\n",
              "          [ 0.7585,  0.7298,  0.6635],\n",
              "          [-0.0100, -0.0208, -0.0225]]),\n",
              "  'std': tensor([[2.4589, 2.3819, 2.4028],\n",
              "          [1.9165, 1.8434, 1.8344],\n",
              "          [2.1524, 2.0766, 2.0886],\n",
              "          [1.9149, 1.8357, 1.8274]])}}"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "for param in SPLAT_RANGES.keys():\n",
        "    SPLAT_RANGES[param][\"mean\"] = torch.tensor(\n",
        "        SPLAT_RANGES[param][\"mean\"], dtype=torch.float32\n",
        "    )\n",
        "    SPLAT_RANGES[param][\"std\"] = torch.tensor(\n",
        "        SPLAT_RANGES[param][\"std\"], dtype=torch.float32\n",
        "    )\n",
        "SPLAT_RANGES"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Label: airplane\n",
            "colors: [-9.533025741577148, 12.163064002990723] -> [-0.9641077518463135, 0.8002510666847229]\n",
            "means: [-1.0, 1.0] -> [-0.9979274272918701, 0.9987775087356567]\n",
            "opacities: [-4.73273229598999, 5.293581008911133] -> [-0.9243193864822388, 0.835913360118866]\n",
            "quats: [-1.6623637676239014, 2.6217942237854004] -> [-0.5537052750587463, 0.5027226805686951]\n",
            "scales: [-10.672653198242188, 3.9764418601989746] -> [-0.9996795654296875, 1.0]\n",
            "===\n",
            "Label: automobile\n",
            "colors: [-10.232390403747559, 11.857702255249023] -> [-0.9708322286605835, 0.8739020228385925]\n",
            "means: [-1.0, 1.0] -> [-0.9979274272918701, 0.9987775087356567]\n",
            "opacities: [-4.8982954025268555, 5.20357608795166] -> [-0.9029794335365295, 0.8699905872344971]\n",
            "quats: [-1.4995923042297363, 2.910125494003296] -> [-0.6938697099685669, 0.5712622404098511]\n",
            "scales: [-11.359330177307129, 4.201854705810547] -> [-0.9996407628059387, 1.0]\n",
            "===\n",
            "Label: bird\n",
            "colors: [-7.313357830047607, 8.84171199798584] -> [-0.9591242671012878, 0.816911518573761]\n",
            "means: [-1.0, 1.0] -> [-0.9979274272918701, 0.9987775087356567]\n",
            "opacities: [-4.565436840057373, 4.05141544342041] -> [-0.9548801779747009, 0.841410219669342]\n",
            "quats: [-1.2440365552902222, 3.366917848587036] -> [-0.6586707830429077, 0.5613754391670227]\n",
            "scales: [-8.187206268310547, 3.7512669563293457] -> [-0.9995256662368774, 1.0]\n",
            "===\n",
            "Label: cat\n",
            "colors: [-11.481281280517578, 13.023453712463379] -> [-0.9658380746841431, 0.6998340487480164]\n",
            "means: [-1.0, 1.0] -> [-0.9979274272918701, 0.9987775087356567]\n",
            "opacities: [-4.612491130828857, 4.653690814971924] -> [-0.9328785538673401, 0.9601823687553406]\n",
            "quats: [-1.3467092514038086, 2.8560562133789062] -> [-0.651943027973175, 0.5166469216346741]\n",
            "scales: [-10.90050220489502, 4.688673496246338] -> [-0.999534010887146, 1.0]\n",
            "===\n",
            "Label: deer\n",
            "colors: [-11.698781967163086, 13.803009986877441] -> [-0.9683241844177246, 0.8216938972473145]\n",
            "means: [-1.0, 1.0] -> [-0.9979274272918701, 0.9987775087356567]\n",
            "opacities: [-4.890936374664307, 4.803365707397461] -> [-0.9120721817016602, 0.907353937625885]\n",
            "quats: [-2.166600227355957, 2.5040700435638428] -> [-0.5786547064781189, 0.6640697121620178]\n",
            "scales: [-10.221508979797363, 3.7017502784729004] -> [-0.9996650218963623, 1.0]\n",
            "===\n",
            "Label: dog\n",
            "colors: [-11.630428314208984, 13.563864707946777] -> [-0.9637771248817444, 0.6805310249328613]\n",
            "means: [-1.0, 1.0] -> [-0.9979274272918701, 0.9987775087356567]\n",
            "opacities: [-4.836583137512207, 5.109440803527832] -> [-0.9226751923561096, 0.8795185089111328]\n",
            "quats: [-1.4494799375534058, 2.961209297180176] -> [-0.6598955392837524, 0.586963415145874]\n",
            "scales: [-8.484810829162598, 3.4842867851257324] -> [-0.9995365738868713, 1.0]\n",
            "===\n",
            "Label: frog\n",
            "colors: [-9.077479362487793, 11.023773193359375] -> [-0.9703987240791321, 0.8930346369743347]\n",
            "means: [-1.0, 1.0] -> [-0.9979274272918701, 0.9987775087356567]\n",
            "opacities: [-4.745082855224609, 5.133230686187744] -> [-0.9242200255393982, 0.9651732444763184]\n",
            "quats: [-1.3585455417633057, 3.601199150085449] -> [-0.6781280040740967, 0.5580016374588013]\n",
            "scales: [-8.516214370727539, 3.759931802749634] -> [-0.9996440410614014, 1.0]\n",
            "===\n",
            "Label: horse\n",
            "colors: [-9.300802230834961, 12.217658996582031] -> [-0.9712315797805786, 0.8457219004631042]\n",
            "means: [-1.0, 1.0] -> [-0.9979274272918701, 0.9987775087356567]\n",
            "opacities: [-4.920316696166992, 4.329853534698486] -> [-0.8929834365844727, 0.8470284938812256]\n",
            "quats: [-1.1897882223129272, 2.364327907562256] -> [-0.594169020652771, 0.5563682317733765]\n",
            "scales: [-8.143842697143555, 3.7462081909179688] -> [-0.999830424785614, 1.0]\n",
            "===\n",
            "Label: ship\n",
            "colors: [-9.046455383300781, 10.8825101852417] -> [-0.9741515517234802, 0.7905954122543335]\n",
            "means: [-1.0, 1.0] -> [-0.9979274272918701, 0.9987775087356567]\n",
            "opacities: [-4.792640686035156, 5.121659278869629] -> [-0.9134075045585632, 0.8331432938575745]\n",
            "quats: [-1.4303817749023438, 2.8786020278930664] -> [-0.66522216796875, 0.6044134497642517]\n",
            "scales: [-9.78883171081543, 4.572704315185547] -> [-0.9996569156646729, 1.0]\n",
            "===\n",
            "Label: truck\n",
            "colors: [-9.640141487121582, 11.17776870727539] -> [-0.9712401628494263, 0.8434150815010071]\n",
            "means: [-1.0, 1.0] -> [-0.9979274272918701, 0.9987775087356567]\n",
            "opacities: [-4.65819787979126, 4.557453155517578] -> [-0.955782949924469, 0.9385344982147217]\n",
            "quats: [-1.429076910018921, 3.4939022064208984] -> [-0.7100047469139099, 0.541629433631897]\n",
            "scales: [-10.177995681762695, 4.081628322601318] -> [-0.9997687935829163, 1.0]\n",
            "===\n"
          ]
        }
      ],
      "source": [
        "# How it was ... Check output!\n",
        "for label, samples in DATA.items():\n",
        "    print(f\"Label: {label}\")\n",
        "    for image, splat in samples:\n",
        "        result = custom_forward(\n",
        "            CUSTOM_MEANS_MODEL,\n",
        "            CUSTOM_QUATS_MODEL,\n",
        "            CUSTOM_SCALES_MODEL,\n",
        "            CUSTOM_OPACITIES_MODEL,\n",
        "            CUSTOM_COLORS_MODEL,\n",
        "            splat,\n",
        "        )\n",
        "        for param, value in result.items():\n",
        "            if param == \"Ks\" or param == \"viewmats\":\n",
        "                continue\n",
        "            print(\n",
        "                f\"{param}: [{splat[param].min()}, {splat[param].max()}] -> [{result[param].min()}, {result[param].max()}]\"\n",
        "            )\n",
        "    print(\"===\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
