{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Note: This is a hack to allow importing from the parent directory\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "sys.path.append(str(Path().resolve().parent))\n",
        "sys.path.append(str(Path().resolve().parent / \"submodules/resnet-18-autoencoder/src\"))\n",
        "\n",
        "# Note: Ignore warnings, be brave (YoLo)\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from utils import noop_collate\n",
        "from models import ResNetAutoencoder\n",
        "from data import CIFAR10GaussianSplatsDataset\n",
        "from constants import CIFAR10_TRANSFORM, CIFAR10_INVERSE_TRANSFORM, TENSOR_TRANSFORM, PIL_TRANSFORM\n",
        "from classes.resnet_autoencoder import AE as DefaultResNetAutoencoder\n",
        "\n",
        "plt.style.use(\"../style/main.mpltstyle\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "def collect_samples_by_label(data, n_samples, test_loader, class_to_index, index_to_class):\n",
        "    data = {k: [] for k in class_to_index.keys()}\n",
        "    all_labels_filled = False  \n",
        "\n",
        "    for batch in test_loader:\n",
        "        if all_labels_filled:\n",
        "            break  \n",
        "\n",
        "        for image, index, splat in batch:\n",
        "            label = index_to_class[index]\n",
        "            if len(data[label]) < n_samples:\n",
        "                data[label].append((image, splat))\n",
        "\n",
        "            all_labels_filled = all(len(v) >= n_samples for v in data.values())\n",
        "            if all_labels_filled:\n",
        "                break  \n",
        "            \n",
        "    return data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "N_SAMPLES = 1\n",
        "CUSTOM_MODEL = None # TODO: ResNetAutoencoder()\n",
        "DEFAULT_MODEL = DefaultResNetAutoencoder(\"light\")\n",
        "DEFAULT_MODEL.load_state_dict(torch.load(\"../models/default_resnet_autoencoder.ckpt\")[\"model_state_dict\"])\n",
        "\n",
        "test_dataset = CIFAR10GaussianSplatsDataset(\n",
        "    root=\"../data/CIFAR10GS\",\n",
        "    test=True,\n",
        "    init_type=\"grid\",\n",
        ")\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size=1,\n",
        "    shuffle=False,\n",
        "    collate_fn=noop_collate,\n",
        ")\n",
        "\n",
        "CLASS_TO_INDEX = test_dataset.class_to_index\n",
        "INDEX_TO_CLASS = {v: k for k, v in CLASS_TO_INDEX.items()}\n",
        "DATA = collect_samples_by_label(test_dataset, N_SAMPLES, test_loader, CLASS_TO_INDEX, INDEX_TO_CLASS)\n",
        "CUSTOM_RESULTS = {k: [] for k in CLASS_TO_INDEX.keys()}\n",
        "DEFAULT_RESULTS = {k: [] for k in CLASS_TO_INDEX.keys()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([[[[1.1197, 1.1803, 1.1692,  ..., 0.7835, 0.8779, 0.8946],\n",
              "           [1.1238, 1.1278, 1.0907,  ..., 0.8138, 0.8201, 0.8807],\n",
              "           [1.1878, 1.0721, 1.0530,  ..., 0.8437, 0.9130, 0.9806],\n",
              "           ...,\n",
              "           [0.9943, 0.9008, 0.8261,  ..., 0.7074, 0.7918, 0.8700],\n",
              "           [0.9253, 0.8998, 0.9483,  ..., 0.6351, 0.9191, 0.9426],\n",
              "           [0.8327, 0.9109, 0.9811,  ..., 0.7297, 0.8181, 0.8234]],\n",
              " \n",
              "          [[1.0307, 1.0070, 0.9696,  ..., 0.7381, 0.7550, 0.7351],\n",
              "           [0.9468, 0.9586, 0.9317,  ..., 0.8063, 0.7246, 0.7352],\n",
              "           [1.0725, 1.0529, 0.9153,  ..., 0.8591, 0.8506, 0.8469],\n",
              "           ...,\n",
              "           [0.8948, 0.8186, 0.7585,  ..., 0.6959, 0.6907, 0.7307],\n",
              "           [0.8874, 0.8810, 0.8579,  ..., 0.6175, 0.7667, 0.7880],\n",
              "           [0.7910, 0.8770, 0.8279,  ..., 0.6568, 0.6113, 0.6072]],\n",
              " \n",
              "          [[0.8719, 0.8555, 0.9379,  ..., 0.6578, 0.6417, 0.6059],\n",
              "           [0.7856, 0.8542, 0.9414,  ..., 0.6846, 0.6402, 0.6467],\n",
              "           [0.9427, 0.8956, 0.8676,  ..., 0.7169, 0.7291, 0.7089],\n",
              "           ...,\n",
              "           [0.8088, 0.7814, 0.7669,  ..., 0.6564, 0.6692, 0.7261],\n",
              "           [0.7841, 0.8391, 0.8969,  ..., 0.6027, 0.7557, 0.7376],\n",
              "           [0.7179, 0.7985, 0.8675,  ..., 0.6635, 0.6260, 0.5982]]]],\n",
              "        grad_fn=<ReluBackward0>),\n",
              " tensor([[[[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
              "            0.0000e+00, 0.0000e+00],\n",
              "           [0.0000e+00, 0.0000e+00, 1.3014e-02,  ..., 0.0000e+00,\n",
              "            0.0000e+00, 0.0000e+00],\n",
              "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
              "            0.0000e+00, 0.0000e+00],\n",
              "           ...,\n",
              "           [0.0000e+00, 2.5174e-02, 3.7421e-02,  ..., 0.0000e+00,\n",
              "            0.0000e+00, 0.0000e+00],\n",
              "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
              "            0.0000e+00, 0.0000e+00],\n",
              "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
              "            0.0000e+00, 0.0000e+00]],\n",
              " \n",
              "          [[1.2897e-01, 1.8448e-01, 9.9062e-02,  ..., 2.7502e-01,\n",
              "            1.8277e-01, 1.9739e-01],\n",
              "           [9.6282e-02, 1.6415e-01, 1.9742e-01,  ..., 3.5391e-01,\n",
              "            1.5791e-01, 1.3500e-01],\n",
              "           [2.4908e-02, 1.7684e-02, 5.3697e-02,  ..., 2.5315e-01,\n",
              "            1.2662e-03, 1.2949e-01],\n",
              "           ...,\n",
              "           [1.6459e-01, 1.5352e-01, 4.6916e-01,  ..., 2.4727e-01,\n",
              "            1.7197e-01, 9.2319e-02],\n",
              "           [1.6648e-01, 7.5638e-02, 3.9112e-01,  ..., 2.8216e-01,\n",
              "            7.3605e-02, 4.0059e-01],\n",
              "           [1.4022e-01, 1.1915e-01, 6.6230e-02,  ..., 5.7247e-02,\n",
              "            3.9905e-01, 1.6437e-01]],\n",
              " \n",
              "          [[3.8920e-01, 1.3501e-01, 2.2266e-01,  ..., 4.9531e-02,\n",
              "            1.1683e-01, 8.6903e-02],\n",
              "           [2.1009e-01, 5.8341e-01, 2.9942e-01,  ..., 4.0325e-01,\n",
              "            2.1230e-01, 1.1287e-01],\n",
              "           [2.1646e-01, 4.5482e-01, 2.6576e-01,  ..., 2.7193e-01,\n",
              "            9.7825e-02, 7.6579e-02],\n",
              "           ...,\n",
              "           [2.8360e-01, 1.5500e-01, 3.0668e-01,  ..., 2.5112e-01,\n",
              "            2.6065e-01, 2.7304e-01],\n",
              "           [4.7948e-01, 3.0515e-01, 1.0141e-01,  ..., 4.7235e-01,\n",
              "            3.3328e-01, 3.8482e-01],\n",
              "           [3.0337e-01, 4.6402e-01, 4.4601e-01,  ..., 2.2545e-01,\n",
              "            2.3870e-01, 3.8205e-01]],\n",
              " \n",
              "          ...,\n",
              " \n",
              "          [[2.4944e-01, 3.0814e-01, 2.4036e-01,  ..., 3.1896e-01,\n",
              "            2.5091e-01, 3.3639e-01],\n",
              "           [6.4195e-01, 2.9053e-01, 4.8576e-01,  ..., 4.5622e-01,\n",
              "            2.9670e-01, 3.4736e-01],\n",
              "           [3.4580e-01, 2.8848e-01, 2.2858e-01,  ..., 3.5809e-01,\n",
              "            2.9300e-01, 2.0476e-01],\n",
              "           ...,\n",
              "           [2.8335e-01, 4.3793e-01, 8.0648e-01,  ..., 3.1657e-01,\n",
              "            2.6408e-01, 2.1881e-01],\n",
              "           [5.6247e-01, 2.9221e-01, 8.4333e-01,  ..., 6.6990e-01,\n",
              "            3.0119e-01, 4.4206e-01],\n",
              "           [3.6368e-01, 2.8812e-01, 4.1732e-01,  ..., 4.2151e-01,\n",
              "            4.1505e-01, 2.6800e-01]],\n",
              " \n",
              "          [[5.9572e-01, 4.5838e-01, 2.8600e-01,  ..., 6.2887e-01,\n",
              "            3.9128e-01, 3.3640e-01],\n",
              "           [4.8135e-01, 3.4219e-01, 6.2722e-01,  ..., 2.5709e-01,\n",
              "            4.1770e-01, 3.7674e-01],\n",
              "           [3.5480e-01, 7.3018e-01, 5.9115e-01,  ..., 5.1899e-01,\n",
              "            3.7504e-01, 3.4078e-01],\n",
              "           ...,\n",
              "           [4.1912e-01, 4.5011e-01, 3.2041e-01,  ..., 4.8344e-01,\n",
              "            4.0098e-01, 4.5959e-01],\n",
              "           [8.3377e-01, 4.4285e-01, 2.5581e-01,  ..., 2.9181e-01,\n",
              "            5.4024e-01, 1.3425e-01],\n",
              "           [3.4681e-01, 7.5493e-01, 4.6918e-01,  ..., 3.9082e-01,\n",
              "            2.8974e-01, 2.4186e-01]],\n",
              " \n",
              "          [[1.1586e+00, 3.7242e-01, 8.8518e-01,  ..., 6.1378e-01,\n",
              "            7.4570e-01, 6.8391e-01],\n",
              "           [1.4391e+00, 5.9610e-02, 3.4173e-01,  ..., 8.1207e-01,\n",
              "            7.1718e-01, 6.7278e-01],\n",
              "           [1.1483e+00, 1.9915e-01, 5.9610e-02,  ..., 7.0771e-01,\n",
              "            6.3127e-01, 5.6900e-01],\n",
              "           ...,\n",
              "           [8.0557e-01, 8.3449e-01, 4.9721e-01,  ..., 5.9610e-02,\n",
              "            5.9610e-02, 3.2917e-01],\n",
              "           [1.1770e+00, 5.9610e-02, 2.3975e-01,  ..., 1.4954e-01,\n",
              "            5.9610e-02, 5.9610e-02],\n",
              "           [1.2480e+00, 7.5623e-01, 5.9610e-02,  ..., 8.5087e-01,\n",
              "            9.2033e-01, 5.7255e-01]]]], grad_fn=<ReluBackward0>))"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "DEFAULT_MODEL(TENSOR_TRANSFORM(DATA[\"airplane\"][0][0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'airplane': [(<PIL.PngImagePlugin.PngImageFile image mode=RGB size=32x32>,\n",
              "   ParameterDict(\n",
              "       (Ks): Parameter containing: [torch.FloatTensor of size 3x3]\n",
              "       (means): Parameter containing: [torch.FloatTensor of size 1024x3]\n",
              "       (opacities): Parameter containing: [torch.FloatTensor of size 1024]\n",
              "       (quats): Parameter containing: [torch.FloatTensor of size 1024x4]\n",
              "       (scales): Parameter containing: [torch.FloatTensor of size 1024x3]\n",
              "       (viewmats): Parameter containing: [torch.FloatTensor of size 4x4]\n",
              "       (colors): Parameter containing: [torch.FloatTensor of size 1024x4x3]\n",
              "   ))],\n",
              " 'automobile': [(<PIL.PngImagePlugin.PngImageFile image mode=RGB size=32x32>,\n",
              "   ParameterDict(\n",
              "       (Ks): Parameter containing: [torch.FloatTensor of size 3x3]\n",
              "       (means): Parameter containing: [torch.FloatTensor of size 1024x3]\n",
              "       (opacities): Parameter containing: [torch.FloatTensor of size 1024]\n",
              "       (quats): Parameter containing: [torch.FloatTensor of size 1024x4]\n",
              "       (scales): Parameter containing: [torch.FloatTensor of size 1024x3]\n",
              "       (viewmats): Parameter containing: [torch.FloatTensor of size 4x4]\n",
              "       (colors): Parameter containing: [torch.FloatTensor of size 1024x4x3]\n",
              "   ))],\n",
              " 'bird': [(<PIL.PngImagePlugin.PngImageFile image mode=RGB size=32x32>,\n",
              "   ParameterDict(\n",
              "       (Ks): Parameter containing: [torch.FloatTensor of size 3x3]\n",
              "       (means): Parameter containing: [torch.FloatTensor of size 1024x3]\n",
              "       (opacities): Parameter containing: [torch.FloatTensor of size 1024]\n",
              "       (quats): Parameter containing: [torch.FloatTensor of size 1024x4]\n",
              "       (scales): Parameter containing: [torch.FloatTensor of size 1024x3]\n",
              "       (viewmats): Parameter containing: [torch.FloatTensor of size 4x4]\n",
              "       (colors): Parameter containing: [torch.FloatTensor of size 1024x4x3]\n",
              "   ))],\n",
              " 'cat': [(<PIL.PngImagePlugin.PngImageFile image mode=RGB size=32x32>,\n",
              "   ParameterDict(\n",
              "       (Ks): Parameter containing: [torch.FloatTensor of size 3x3]\n",
              "       (means): Parameter containing: [torch.FloatTensor of size 1024x3]\n",
              "       (opacities): Parameter containing: [torch.FloatTensor of size 1024]\n",
              "       (quats): Parameter containing: [torch.FloatTensor of size 1024x4]\n",
              "       (scales): Parameter containing: [torch.FloatTensor of size 1024x3]\n",
              "       (viewmats): Parameter containing: [torch.FloatTensor of size 4x4]\n",
              "       (colors): Parameter containing: [torch.FloatTensor of size 1024x4x3]\n",
              "   ))],\n",
              " 'deer': [(<PIL.PngImagePlugin.PngImageFile image mode=RGB size=32x32>,\n",
              "   ParameterDict(\n",
              "       (Ks): Parameter containing: [torch.FloatTensor of size 3x3]\n",
              "       (means): Parameter containing: [torch.FloatTensor of size 1024x3]\n",
              "       (opacities): Parameter containing: [torch.FloatTensor of size 1024]\n",
              "       (quats): Parameter containing: [torch.FloatTensor of size 1024x4]\n",
              "       (scales): Parameter containing: [torch.FloatTensor of size 1024x3]\n",
              "       (viewmats): Parameter containing: [torch.FloatTensor of size 4x4]\n",
              "       (colors): Parameter containing: [torch.FloatTensor of size 1024x4x3]\n",
              "   ))],\n",
              " 'dog': [(<PIL.PngImagePlugin.PngImageFile image mode=RGB size=32x32>,\n",
              "   ParameterDict(\n",
              "       (Ks): Parameter containing: [torch.FloatTensor of size 3x3]\n",
              "       (means): Parameter containing: [torch.FloatTensor of size 1024x3]\n",
              "       (opacities): Parameter containing: [torch.FloatTensor of size 1024]\n",
              "       (quats): Parameter containing: [torch.FloatTensor of size 1024x4]\n",
              "       (scales): Parameter containing: [torch.FloatTensor of size 1024x3]\n",
              "       (viewmats): Parameter containing: [torch.FloatTensor of size 4x4]\n",
              "       (colors): Parameter containing: [torch.FloatTensor of size 1024x4x3]\n",
              "   ))],\n",
              " 'frog': [(<PIL.PngImagePlugin.PngImageFile image mode=RGB size=32x32>,\n",
              "   ParameterDict(\n",
              "       (Ks): Parameter containing: [torch.FloatTensor of size 3x3]\n",
              "       (means): Parameter containing: [torch.FloatTensor of size 1024x3]\n",
              "       (opacities): Parameter containing: [torch.FloatTensor of size 1024]\n",
              "       (quats): Parameter containing: [torch.FloatTensor of size 1024x4]\n",
              "       (scales): Parameter containing: [torch.FloatTensor of size 1024x3]\n",
              "       (viewmats): Parameter containing: [torch.FloatTensor of size 4x4]\n",
              "       (colors): Parameter containing: [torch.FloatTensor of size 1024x4x3]\n",
              "   ))],\n",
              " 'horse': [(<PIL.PngImagePlugin.PngImageFile image mode=RGB size=32x32>,\n",
              "   ParameterDict(\n",
              "       (Ks): Parameter containing: [torch.FloatTensor of size 3x3]\n",
              "       (means): Parameter containing: [torch.FloatTensor of size 1024x3]\n",
              "       (opacities): Parameter containing: [torch.FloatTensor of size 1024]\n",
              "       (quats): Parameter containing: [torch.FloatTensor of size 1024x4]\n",
              "       (scales): Parameter containing: [torch.FloatTensor of size 1024x3]\n",
              "       (viewmats): Parameter containing: [torch.FloatTensor of size 4x4]\n",
              "       (colors): Parameter containing: [torch.FloatTensor of size 1024x4x3]\n",
              "   ))],\n",
              " 'ship': [(<PIL.PngImagePlugin.PngImageFile image mode=RGB size=32x32>,\n",
              "   ParameterDict(\n",
              "       (Ks): Parameter containing: [torch.FloatTensor of size 3x3]\n",
              "       (means): Parameter containing: [torch.FloatTensor of size 1024x3]\n",
              "       (opacities): Parameter containing: [torch.FloatTensor of size 1024]\n",
              "       (quats): Parameter containing: [torch.FloatTensor of size 1024x4]\n",
              "       (scales): Parameter containing: [torch.FloatTensor of size 1024x3]\n",
              "       (viewmats): Parameter containing: [torch.FloatTensor of size 4x4]\n",
              "       (colors): Parameter containing: [torch.FloatTensor of size 1024x4x3]\n",
              "   ))],\n",
              " 'truck': [(<PIL.PngImagePlugin.PngImageFile image mode=RGB size=32x32>,\n",
              "   ParameterDict(\n",
              "       (Ks): Parameter containing: [torch.FloatTensor of size 3x3]\n",
              "       (means): Parameter containing: [torch.FloatTensor of size 1024x3]\n",
              "       (opacities): Parameter containing: [torch.FloatTensor of size 1024]\n",
              "       (quats): Parameter containing: [torch.FloatTensor of size 1024x4]\n",
              "       (scales): Parameter containing: [torch.FloatTensor of size 1024x3]\n",
              "       (viewmats): Parameter containing: [torch.FloatTensor of size 4x4]\n",
              "       (colors): Parameter containing: [torch.FloatTensor of size 1024x4x3]\n",
              "   ))]}"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "for label, samples in DATA.items():\n",
        "    for image, splat in samples:\n",
        "        if CUSTOM_MODEL:\n",
        "            CUSTOM_RESULTS[label].append(CUSTOM_MODEL(image, splat))\n",
        "        if DEFAULT_MODEL:\n",
        "            DEFAULT_RESULTS[label].append(DEFAULT_MODEL(image, splat))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
